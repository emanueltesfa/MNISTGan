{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V3E9i7apvIG"
      },
      "source": [
        "## GAN starter code\n",
        "Corresponding tutorial: [https://youtu.be/_pIMdDWK5sc](https://youtu.be/_pIMdDWK5sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PyiTpiVaKuHT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
            "     -------------------------------------- 827.8/827.8 kB 3.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from pytorch-lightning) (1.12.1)\n",
            "Requirement already satisfied: packaging>=17.1 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from pytorch-lightning) (22.0)\n",
            "Collecting fsspec[http]>2021.06.0\n",
            "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
            "     -------------------------------------- 145.4/145.4 kB 8.4 MB/s eta 0:00:00\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
            "     -------------------------------------- 518.6/518.6 kB 3.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from pytorch-lightning) (4.4.0)\n",
            "Collecting lightning-utilities>=0.6.0.post0\n",
            "  Downloading lightning_utilities-0.7.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: requests in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.28.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-win_amd64.whl (323 kB)\n",
            "     -------------------------------------- 323.6/323.6 kB 2.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: colorama in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-win_amd64.whl (34 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-win_amd64.whl (56 kB)\n",
            "     ---------------------------------------- 56.8/56.8 kB 2.9 MB/s eta 0:00:00\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amant\\anaconda3\\envs\\dl\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Installing collected packages: multidict, lightning-utilities, fsspec, frozenlist, async-timeout, yarl, torchmetrics, aiosignal, aiohttp, pytorch-lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 fsspec-2023.3.0 lightning-utilities-0.7.1 multidict-6.0.4 pytorch-lightning-1.9.4 torchmetrics-0.11.3 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcwy4eyFLPz0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "BATCH_SIZE=128\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "NUM_WORKERS=int(os.cpu_count() / 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IifHZX-vLVEN"
      },
      "outputs": [],
      "source": [
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, data_dir=\"./data\", \n",
        "                 batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def prepare_data(self):\n",
        "        MNIST(self.data_dir, train=True, download=True)\n",
        "        MNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Assign train/val datasets\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
        "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
        "\n",
        "        # Assign test dataset\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa0rSLKuLrf1"
      },
      "outputs": [],
      "source": [
        "# Detective: fake or no fake -> 1 output [0, 1]\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Simple CNN\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "  \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        # Flatten the tensor so it can be fed into the FC layers\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFa6X5ELLdFJ"
      },
      "outputs": [],
      "source": [
        "# Generate Fake Data: output like real data [1, 28, 28] and values -1, 1\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(latent_dim, 7*7*64)  # [n, 256, 7, 7]\n",
        "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
        "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
        "        self.conv = nn.Conv2d(16, 1, kernel_size=7)  # [n, 1, 28, 28]\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass latent space input into linear layer and reshape\n",
        "        x = self.lin1(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1, 64, 7, 7)  #256\n",
        "        \n",
        "        # Upsample (transposed conv) 16x16 (64 feature maps)\n",
        "        x = self.ct1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Upsample to 34x34 (16 feature maps)\n",
        "        x = self.ct2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Convolution to 28x28 (1 feature map)\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LvSFp-5LuAJ"
      },
      "outputs": [],
      "source": [
        "# TODO: GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgaTg52NcVzr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5i4KvKhcaoD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2Pm5NBcptwY"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
